#   hive-metastore:
#     image: apache/hive:3.1.3
#     platform: linux/amd64
#     container_name: hive-metastore
#     environment:
#       - SERVICE_NAME=metastore
#       - HIVE_METASTORE_DB_TYPE=postgres
#       - HIVE_METASTORE_URI=thrift://0.0.0.0:9083
#     ports:
#       - "9083:9083"
#     depends_on:
#       - namenode
#       - datanode
#       - postgres
#     networks:
#       - kafka-net

#   hive-server:
#     image: apache/hive:3.1.3
#     platform: linux/amd64
#     container_name: hive-server
#     environment:
#       - SERVICE_NAME=hiveserver2
#       - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
#     ports:
#       - "10000:10000"
#     depends_on:
#       - hive-metastore
#     networks:
#       - kafka-net

#   jupyter:
#     image: easewithdata/pyspark-jupyter-lab
#     user: root
#     platform: linux/amd64
#     container_name: jupyter
#     ports:
#       - 8888:8888
#       - 4040:4040
#     environment:
#       JUPYTER_PORT: 8888
#       SPARK_UI_PORT: 4040
#       GRANT_SUDO: yes
#     volumes:
#       - streaming_data:/data:rw
#     networks:
#       - kafka-ne

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    platform: linux/amd64
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - cloudflare

  kafka:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka
    platform: linux/amd64
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DELETE_TOPIC_ENABLE: "true"
    networks:
      - cloudflare
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    platform: linux/amd64
    ports:
      - "8080:8080"
    depends_on:
      - kafka
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
    networks:
      - cloudflare

  producer:
    build: ./producer
    container_name: producer
    platform: linux/amd64
    environment:
      - LOKI_URL=https://loki.example.com
      - KAFKA_BROKER=kafka:9092
      - KAFKA_DNS_TOPIC=dns
      - KAFKA_FIREWALL_TOPIC=firewall
    depends_on:
      - kafka
      - kafka-ui
      - zookeeper
    networks:
      - cloudflare

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    platform: linux/amd64
    container_name: namenode
    restart: always
    ports:
      - "9870:9870"  # Web UI
      - "8020:8020"  # HDFS
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=hadoop-cluster
      - INIT_DAEMON_STEP=setup
    env_file:
      - ./hadoop.env
    networks:
      - cloudflare

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    platform: linux/amd64
    container_name: datanode
    restart: always
    depends_on:
      - namenode
    volumes:
      - datanode:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    networks:
      - cloudflare

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    platform: linux/amd64
    container_name: resourcemanager
    restart: always
    depends_on:
      - namenode
    ports:
      - "8088:8088"  # YARN Web UI
    env_file:
      - ./hadoop.env
    networks:
      - cloudflare

  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    platform: linux/amd64
    container_name: nodemanager
    restart: always
    depends_on:
      - resourcemanager
    env_file:
      - ./hadoop.env
    networks:
      - cloudflare

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    platform: linux/amd64
    container_name: historyserver
    restart: always
    depends_on:
      - namenode
    ports:
      - "8188:8188"
    env_file:
      - ./hadoop.env
    networks:
      - cloudflare

  postgres:
    image: postgres:15.3
    container_name: postgres
    # platform: linux/amd64
    restart: always
    environment:
      POSTGRES_USER: superset
      POSTGRES_PASSWORD: superset
      POSTGRES_DB: dns_logs
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 1s
      timeout: 5s
      retries: 10
    ports:
      - "5432:5432"
    networks:
      - cloudflare
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql

  superset:
    image: apache/superset
    container_name: superset
    platform: linux/amd64
    ports:
      - "8089:8088"
    depends_on:
      - postgres
    volumes:
      - ./requirements-local.txt:/app/requirements-local.txt
    environment:
      SUPERSET_LOAD_EXAMPLES: "no"
      SUPERSET_SECRET_KEY: "superset"
      DATABASE_URL: postgresql+psycopg2://superset:superset@postgres:5432/dns_logs
    command: >
      /bin/sh -c "
      pip install -r /app/requirements-local.txt &&
      superset db upgrade &&
      superset fab create-admin --username admin --firstname Admin --lastname User --email admin@superset.com --password admin &&
      superset init &&
      superset run -h 0.0.0.0 -p 8088 --with-threads --reload --debugger"
    networks:
      - cloudflare

  # consumer:
  #   build: ./consumer
  #   container_name: consumer
  #   depends_on:
  #     - kafka
  #     - spark-master
  #     - spark-worker
  #     - namenode
  #     - datanode
  #   environment:
  #     KAFKA_BROKER: kafka:9092
  #     KAFKA_DNS_TOPIC: dns
  #     HDFS_URI: hdfs://hadoop-namenode:9000
  #   volumes:
  #     - ./checkpoints:/tmp/spark_checkpoint_dns
  #   command: [
  #     "/opt/spark/bin/spark-submit",
  #     "--packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0,org.apache.hadoop:hadoop-common:3.2.1,org.postgresql:postgresql:42.2.20",
  #     "--master", "spark://spark-master:7077",
  #     "app.py"
  #   ]
  #   networks:
  #     - cloudflare

  consumer:
    image: bitnami/spark:latest
    container_name: consumer
    platform: linux/amd64
    depends_on:
      - kafka
    volumes:
      - ./app:/app
    working_dir: /app
    command: >
      bash -c "
        pip install kafka-python &&
        spark-submit --master spark://spark-master:7077 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0,org.postgresql:postgresql:42.2.20 /app/spark_app.py
      "
    networks:
      - cloudflare

  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    platform: linux/amd64
    environment:
      - SPARK_MODE=master
    ports:
      - "8082:8080"  # Spark master UI
    networks:
      - cloudflare

  spark-worker:
    image: bitnami/spark:latest
    container_name: spark-worker
    platform: linux/amd64
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master
    networks:
      - cloudflare

networks:
  cloudflare:
    driver: bridge

volumes:
  namenode:
  datanode:
  pg_data: